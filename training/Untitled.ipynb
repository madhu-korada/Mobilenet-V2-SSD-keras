{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/suraj/suraj/novus/novus_pilot_deep_learning/ssd_keras_updated/')\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,CSVLogger,TerminateOnNaN, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.keras_mobilenet_feature_fuse import ssd_300\n",
    "from utils_1.keras_ssd_loss import SSDLoss, FocalLoss, weightedSSDLoss, weightedFocalLoss\n",
    "from utils_1.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from utils_1.keras_layer_L2Normalization import L2Normalization\n",
    "from utils_1.ssd_box_encode_decode_utils import SSDBoxEncoder, decode_y, decode_y2\n",
    "from utils_1.ssd_batch_generator import BatchGenerator\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "import os\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "img_height = 300  # Height of the input images\n",
    "img_width = 300  # Width of the input images\n",
    "img_channels = 3  # Number of color channels of the input images\n",
    "subtract_mean = [123, 117, 104]  # The per-channel mean of the images in the dataset\n",
    "swap_channels = True  # The color channel order in the original SSD is BGR\n",
    "n_classes = 2  # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_voc = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88,\n",
    "              1.05]  # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87,\n",
    "               1.05]  # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
    "scales = scales_coco\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]]  # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 100, 300]  # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5,\n",
    "           0.5]  # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "limit_boxes = False  # Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2,\n",
    "             0.2]  # The variances by which the encoded target coordinates are scaled as in the original implementation\n",
    "coords = 'centroids'  # Whether the box coordinates to be used as targets for the model should be in the 'centroids', 'corners', or 'minmax' format, see documentation\n",
    "normalize_coords = True\n",
    "\n",
    "# 1: Build the Keras model\n",
    "\n",
    "K.clear_session()  # Clear previous models from memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet is on !!!!!!!!!!!!!!!!!!\n",
      "Training the base network also\n",
      "fc7_2 shape (?, ?, ?, 256)\n",
      "conv4_3_norm shape (?, 38, 38, 256)\n",
      "fc7 shape (?, 19, 19, 512)\n",
      "conv6_2 shape (?, 10, 10, 1024)\n",
      "srjm (?, 10, 10, 128)\n",
      "conv7_2 shape (?, 5, 5, 256)\n",
      "conv8_2 shape (?, 3, 3, 256)\n",
      "conv9_2 shape (?, 1, 1, 256)\n",
      "in training mode\n"
     ]
    }
   ],
   "source": [
    "model = ssd_300(layers = \"all\",\n",
    "                mode = 'training',\n",
    "\t\t\t\t        image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                limit_boxes=limit_boxes,\n",
    "                variances=variances,\n",
    "                coords=coords,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=subtract_mean,\n",
    "                divide_by_stddev=None,\n",
    "                swap_channels=swap_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p ='/home/suraj/suraj/ssd300_epoch-499.h5'\n",
    "\n",
    "model.load_weights(p, by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
